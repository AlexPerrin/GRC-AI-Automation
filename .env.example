# Copy this file to .env and fill in your values.
# Never commit .env to version control.

# ----- LLM Provider -----
# Options: "anthropic" | "openai" | "openrouter"
LLM_PROVIDER=anthropic

# Model ID passed to litellm (after the provider prefix).
# anthropic  → claude-sonnet-4-6
# openai     → gpt-4o
# openrouter → anthropic/claude-sonnet-4-6  (full routed path)
LLM_MODEL=claude-sonnet-4-6

LLM_PROVIDER_API_KEY=                   # API key for the selected provider

# ----- Database -----
# Local dev: relative path (file created next to main.py)
# Docker:    overridden by docker-compose to sqlite:////app/data/vendor_onboarding.db
DATABASE_URL=sqlite:///./vendor_onboarding.db

# ----- ChromaDB -----
# Local dev: embedded PersistentClient — set CHROMA_HOST to empty string
# Docker:    overridden by docker-compose; HttpClient connects to chromadb service
CHROMA_PERSIST_DIR=./chroma_data
CHROMA_HOST=                            # leave blank for local embedded mode
CHROMA_PORT=8000

# ----- Embeddings -----
# Local (default, no API cost): all-MiniLM-L6-v2
# Remote (higher quality):      text-embedding-3-small  (requires OPENAI_API_KEY)
EMBEDDING_MODEL=all-MiniLM-L6-v2
